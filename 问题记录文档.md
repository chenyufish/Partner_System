# 开发过程中遇到的小问题和注意事项

* 开发框架一定要去看官方的最新文档，比如vant3到vant4就修改了Toast的轻提示方法，改为showTaost了

* 标签查询假如速度变慢的怎么办（用户大概超过20w），就要引入缓存技术了（缓存技术还可以用并发线程进行加速），实际上具体选择什么查询，可以去测量一下

* 关联查询很影响扩展性以及查询性能，最大级数应该不超过三重

* 用Gson里面的gson.fromJson(tagstr,new TypeToken<Set<String>>(){}.getType());既可以得到反序列化，因为java里面不支持直接拿去String<List>,所以我们就new一个TypeToken的一个泛型去get一个对象，相反可以使用tojson得到序列化

* 不使用List而使用Set优化时间复杂度

* 如果数据在1万以内的话，for循环效率高于foreach和stream；如果数据量在10万的时候，stream效率最高，其次是foreach,最后是for。

  另外需要注意的是如果数据达到100万的话，[parallelStream](https://so.csdn.net/so/search?q=parallelStream&spm=1001.2101.3001.7020)异步并行处理效率最高，高于foreach和for。并行流（ParallelStream）怎么会比顺序流（Stream）还要慢。。

  实际上并行流（ParallelStream）的背后其实是 Java7 开始支持的 Fork/Join，即把一个大任务拆分成 N 个小任务，然后最终合并各个子任务的结果，所以对于子任务线程的拆分、创建、结果合并等操作都需要不少的开销，特别是线程的创建。

  所以不耗时的简单排序操作事实上是不适用于并行流（ParallelStream）的，它所带来的线程创建的损耗可能还会比顺序流（Stream）还要更慢。
  既然使用 [Fork/Join](https://mp.weixin.qq.com/s/YQa2_daDZbJsTxrqv45-QQ) 是会有损耗的，那对于单条数据的处理的时间最好是理论上要超过用并行流（ParallelStream）本身的损耗，这种情况下就比较合适。

* 在java里面任何集合都要判断空

* 对于加了序列化的注册程序来说，直接在数据库里面增加账号是不能访问的，要调用注册接口实现账号增加

* 单机登录改为分布式登录，允许多台服务器登录对用户进行更改

* 关于用户头像，我们可以设计一个防盗链referrer，但是这个仅仅适用于前端，如果从后台请求的话可以伪造请求方依旧可以拿到头像。可以在index里面加<meta name="referrer"content="none"/>进行伪装，如果别人禁用了no-referrer，那么就拿不到

* SpringMvc一般会自动映射GET方法传参的值

* 跨域是浏览器层面的问题，当我们的协议号或者端口号，或者域名不一样的时候，留啦起就会认为不安全而拒绝我们的访问

* 关于前端和后端请求参数失败了有一种可能是请求的参数格式有问题。解决方法要么修改前端的list改为数组，要么使用axios的序列化![image-20240325174313866](C:\Users\fishman\AppData\Roaming\Typora\typora-user-images\image-20240325174313866.png)

  序列化里面的indecis是请求是形式

  ![image-20240325175347085](C:\Users\fishman\AppData\Roaming\Typora\typora-user-images\image-20240325175347085.png)

  

* http一般以4（400,401）开头的错误码一般都是用户方面的问题

* 对于同一个前端来说，哪怕是不同端口，但如果是同一个域名下，种出来的cookie是一样的会相互覆盖影响

* 如果执行Mavan的生命周期里面的package出现Test报错，那么就是test里面有错误的地方没有跳过，可以使用命令

  ```
  mvn package -DskipTests=true
  ```

  或者在pom里面改跳过，或者关掉小闪电

* 在启动前端dev的时候出现了error when starting dev server:                                 Error: listen EACCES: permission denied 127.0.0.1:5173 

  应该是端口占用了，可以用netstat查看端口，或者直接换端口启动npm run dev -- --port 81

* JWT比较适合有效期短一点，一次性的验证，另外JWT配置起来也有点麻烦，使用session加上redis集成了spring，简单操作易维护

* spring security更是重量级的产物，里面的权限更是细分

* 做登录页面的时候会因为前端的cookie没有传输给后端导致获取当前用户信息失败，响应信息会显示未登录，根据浏览器cookie发现已经种好了，但是Axios发送请求的时候好像没带上cookie

* 在vue route3版本以上自动把hash模式改为了history模式，网址默认不加#，可以使用：history 对应 createWebHistory
  hash 对应 createWebHashHistory改成hash

* cookie的问题一般只会和domain和path有关，假如前后端的端口号或则协议号不一样，会因为浏览器的同源保护机制阻止cookie的请求引入，要解决这个问题需要在前端axios里面开启axios.defaults.withCredentials = true;同时在后端的webmvcconfig里面开启Access-Control-Allow-Credentials: true以及增加跨域端口号

* 由于前端的axios对respon又进行了一层的封装，所以在搜索结果页面，在序列化打平的时候要把respon.data.data改为respond.data

  ![image-20240326203403768](C:\Users\fishman\AppData\Roaming\Typora\typora-user-images\image-20240326203403768.png)

* axios 默认是异步请求，若想等请求返回数据后再往下执行代码，请在需要调用axios的方法前加 [async](https://so.csdn.net/so/search?q=async&spm=1001.2101.3001.7020) 关键字，且在调用axios请求时加上 await 关键字发送同步请求。

* JavaScript里面有一个动态获取用户方法，使用中括号[editUser.value.editKey]: editUser.value.currentValue // 动态取值

* 面对小量的用户，前端并不是很需要使用缓存，直接使用Axios去get currentuser

* 一次性任务可以使用main方法，也可以使用定时任务的方法，如果没有引入@Bean，那么spring就不能进行托管，同时也就使用不了@Resource

* 可以用stopwatch对任务进行时间监视

* userService里面有一个savaBatch方法，这个是mybatis封装好的方法，用来批量插入![image-20240327190233227](C:\Users\fishman\AppData\Roaming\Typora\typora-user-images\image-20240327190233227.png)

* 进行异步任务的时候不能把类似j++这些非原子性的语句放进去，在并发的条件下不好处理j++的先后问题

* 对于cpu密集型（就是使用cpu进行计算偏多一些），默认线程池的线程数量为cpu核数-1，对于IO密集型（就是执行数据传输，硬盘读写的任务），默认线程数是可以超过cpu核数的，如果要自定义线程池，

  ![image-20240327194412230](C:\Users\fishman\AppData\Roaming\Typora\typora-user-images\image-20240327194412230.png)就使用new threadPoolExecutor（corePoolSize：60（这是指定的线程数），maximunPoolSize：1000（这是最大的线程数），keepAliveTime：10000 （这是每个线程的的执行任务数量），TimeUnit.MINUTES，new ArrayBlockQueue<>（capacity：10000）（这个是总任务，如果任务数量超过这个限制，就会在60的基础上增加，直到增加到最大的1000，如果还不够，默认策略就会抛出异常拒绝任务）)

* 当数据库有100w条数据我到前端进入推荐页的时候就卡死了，数据量太多塞进浏览器肯定出问题，引入mybatis-plus的page进行分页管理

* 关系型数据库（mysql使用表来存数据，而且大部分数据放在硬盘里面，小部分也会放到内存）和非关系型数据库（redis里面的nosql，使用K-V键值对储存数据）

* netty更偏向于网络层面。里面是一些封装好的socket的网络传输，相比于redis入门更难，可以用来做类微信app

* redis会默认给存入的数据进行序列化操作，我们需要配置一个redis的config反序列化自己去指定序列化器

* 一定一定要设置redis缓存的过期时间，如果不设置会一直存在，等到满了以后会触发redis自己的缓存清除机制，如果清除到重要信息直接寄了！！！

* 定时任务缓存爆了空指针的异常，一般使用try-catch对异常进行抓取同时打印一个问题日志

* redis缓存雪崩和缓存穿透问题：

* 使用synchronized关键字加锁，是无法分辨是否具有其他服务器的，本地锁管不了多台服务器，只对单个jvm有效

* 如果线程挂掉（注意 debug 模式也会被它当成服务器宕机），则不会续期，测试看门狗的机制时候遇到的bug，还以为是机制失效了

* （可以理解为分布式的分布式锁）如果redis是一个集群，分主群和分群，有出现类似的抢锁怎么办，或者是有redis宕机了怎么办，，要利用redisson里面的一个红锁机制，好像是要什么半数redis服务器进行投票，超过以后推荐新的主群或者是获得锁

* 封装一个dto请求参数包装类：请求参数名称不一样，有一些请求参数用不到，如果加载到接口文档会影响理解成本，还有一种就是多个实体类映射到同一个对象

* 封装响应类才是为了安全

* 为什么需要包装类，一是有些信息不能返回到前端，二是有些字段或者有些方法是不关心的

* ```java
  @Transactional(rollbackFor = Exception.class)
  //加一个事务，如果事务出现问题就抛异常（要么都成功，要么报错不执行）
  ```

* 将类实例序列化以后便于在网络上传输、储存或者在内存中进行缓存，包括持久化储存，缓存、跨平台兼容性，使用序列化UID可以保持序列化和反序列化的过程中保证数据不变，包括版本控制，兼容性问题以及安全性

* 使用Redis实现分布式Session,解决集群间登录态同步问题；并使用Hash代替String来存储用户信息，节约了15%的内存并便于单字段的修改。（需要自己实际测试对比数据，节省内存的原因是不用保存序列化对象信息或者JSON的一些额外字符串)

* A. 悲观锁（排他锁）

  利用`select … where xx=yy for update`排他锁

  注意：这里需要注意的是`where xx=yy`，xx字段**必须要走索引，否则会锁表**。有些情况下，比如表不大，mysql优化器会不走这个索引，导致锁表问题。

  B. 乐观锁
  所谓乐观锁与悲观锁最大区别在于基于CAS思想，表中添加一个时间戳或者是版本号的字段来实现，update xx set version=new_version where xx=yy and version=Old_version，通过增加递增的版本号字段实现乐观锁。

  不具有互斥性，不会产生锁等待而消耗资源，操作过程中认为不存在并发冲突，只有update version失败后才能觉察到。

  抢购、秒杀就是用了这种实现以防止超卖。

* 要对前端传入的过期时间expireTime != null判空，否则进行日期转化成Data的时候会报空指针异常

* 时间格式的序列化问题我们可以用@JsonFormat(pattern = "yyyy-MM-dd", timezone = "GMT+8")

* 出现这种错误的时候，我的建议是好好看看IDEA生成的SQL查询语句，你会发现问题的

  ```java
  \### Error querying database.  Cause: java.sql.SQLSyntaxErrorException: Unknown column 'isDelete' in 'where clause' ### The error may exist in com/yupi/usercenter/mapper/TeamMapper.java (best guess)
  ```

* 由于属性的 ID 是由 mp 内部的 UUID 生成，比如使用 Integer类型 将存不进去。当后端传入 mp 雪花算法自动生成的 ID 时，前端接收的时候可能会导致精度的损失。当没有设定自增策略的时候会使用默认的雪花算法生成id，需要在实体类里面使用

  ```java
  @TableId(value = "id",type = IdType.AUTO)
      private Long id;
  ```

* 